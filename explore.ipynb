{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric import nn as gnn\n",
    "\n",
    "from graph_vae import GraphVAE\n",
    "from train import train_loop\n",
    "from data_load import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GraphVAE(3, 32, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17458.7617, grad_fn=<AddBackward0>)\n",
      "tensor(3760.3674, grad_fn=<AddBackward0>)\n",
      "tensor(4445.9570, grad_fn=<AddBackward0>)\n",
      "tensor(1709.0088, grad_fn=<AddBackward0>)\n",
      "tensor(865.3027, grad_fn=<AddBackward0>)\n",
      "tensor(869.9142, grad_fn=<AddBackward0>)\n",
      "tensor(1018.0605, grad_fn=<AddBackward0>)\n",
      "tensor(1020.2689, grad_fn=<AddBackward0>)\n",
      "tensor(830.9327, grad_fn=<AddBackward0>)\n",
      "tensor(1081.3490, grad_fn=<AddBackward0>)\n",
      "tensor(1198.4775, grad_fn=<AddBackward0>)\n",
      "tensor(820.4479, grad_fn=<AddBackward0>)\n",
      "tensor(1066.0054, grad_fn=<AddBackward0>)\n",
      "tensor(693.0328, grad_fn=<AddBackward0>)\n",
      "tensor(759.8748, grad_fn=<AddBackward0>)\n",
      "tensor(853.5504, grad_fn=<AddBackward0>)\n",
      "tensor(841.3351, grad_fn=<AddBackward0>)\n",
      "tensor(773.8970, grad_fn=<AddBackward0>)\n",
      "tensor(783.3469, grad_fn=<AddBackward0>)\n",
      "tensor(689.9230, grad_fn=<AddBackward0>)\n",
      "tensor(610.6694, grad_fn=<AddBackward0>)\n",
      "tensor(784.0884, grad_fn=<AddBackward0>)\n",
      "tensor(687.3868, grad_fn=<AddBackward0>)\n",
      "tensor(742.4551, grad_fn=<AddBackward0>)\n",
      "tensor(828.5830, grad_fn=<AddBackward0>)\n",
      "tensor(721.9028, grad_fn=<AddBackward0>)\n",
      "tensor(603.3046, grad_fn=<AddBackward0>)\n",
      "tensor(633.9919, grad_fn=<AddBackward0>)\n",
      "tensor(594.7704, grad_fn=<AddBackward0>)\n",
      "tensor(578.3005, grad_fn=<AddBackward0>)\n",
      "tensor(763.0402, grad_fn=<AddBackward0>)\n",
      "tensor(724.1555, grad_fn=<AddBackward0>)\n",
      "tensor(568.2424, grad_fn=<AddBackward0>)\n",
      "tensor(752.8257, grad_fn=<AddBackward0>)\n",
      "tensor(604.5617, grad_fn=<AddBackward0>)\n",
      "tensor(559.5701, grad_fn=<AddBackward0>)\n",
      "tensor(624.2769, grad_fn=<AddBackward0>)\n",
      "tensor(600.5156, grad_fn=<AddBackward0>)\n",
      "tensor(776.6537, grad_fn=<AddBackward0>)\n",
      "tensor(564.4286, grad_fn=<AddBackward0>)\n",
      "tensor(461.6441, grad_fn=<AddBackward0>)\n",
      "tensor(1048.8677, grad_fn=<AddBackward0>)\n",
      "tensor(582.2509, grad_fn=<AddBackward0>)\n",
      "tensor(543.2794, grad_fn=<AddBackward0>)\n",
      "tensor(511.2717, grad_fn=<AddBackward0>)\n",
      "tensor(579.7219, grad_fn=<AddBackward0>)\n",
      "tensor(460.7125, grad_fn=<AddBackward0>)\n",
      "tensor(499.2098, grad_fn=<AddBackward0>)\n",
      "tensor(669.9777, grad_fn=<AddBackward0>)\n",
      "tensor(638.6037, grad_fn=<AddBackward0>)\n",
      "tensor(561.2627, grad_fn=<AddBackward0>)\n",
      "tensor(486.0724, grad_fn=<AddBackward0>)\n",
      "tensor(764.8990, grad_fn=<AddBackward0>)\n",
      "tensor(548.2822, grad_fn=<AddBackward0>)\n",
      "tensor(478.0548, grad_fn=<AddBackward0>)\n",
      "tensor(672.8699, grad_fn=<AddBackward0>)\n",
      "tensor(544.1609, grad_fn=<AddBackward0>)\n",
      "tensor(566.8423, grad_fn=<AddBackward0>)\n",
      "tensor(665.2256, grad_fn=<AddBackward0>)\n",
      "tensor(682.5795, grad_fn=<AddBackward0>)\n",
      "tensor(486.8137, grad_fn=<AddBackward0>)\n",
      "tensor(451.2721, grad_fn=<AddBackward0>)\n",
      "tensor(439.3238, grad_fn=<AddBackward0>)\n",
      "tensor(597.1900, grad_fn=<AddBackward0>)\n",
      "tensor(472.2193, grad_fn=<AddBackward0>)\n",
      "tensor(533.2640, grad_fn=<AddBackward0>)\n",
      "tensor(502.3889, grad_fn=<AddBackward0>)\n",
      "tensor(725.4044, grad_fn=<AddBackward0>)\n",
      "tensor(519.4645, grad_fn=<AddBackward0>)\n",
      "tensor(540.7203, grad_fn=<AddBackward0>)\n",
      "tensor(457.9030, grad_fn=<AddBackward0>)\n",
      "tensor(473.3973, grad_fn=<AddBackward0>)\n",
      "tensor(466.7026, grad_fn=<AddBackward0>)\n",
      "tensor(459.1593, grad_fn=<AddBackward0>)\n",
      "tensor(498.4304, grad_fn=<AddBackward0>)\n",
      "tensor(438.9078, grad_fn=<AddBackward0>)\n",
      "tensor(437.2736, grad_fn=<AddBackward0>)\n",
      "tensor(498.8768, grad_fn=<AddBackward0>)\n",
      "tensor(433.9663, grad_fn=<AddBackward0>)\n",
      "tensor(409.8053, grad_fn=<AddBackward0>)\n",
      "tensor(475.8279, grad_fn=<AddBackward0>)\n",
      "tensor(431.4515, grad_fn=<AddBackward0>)\n",
      "tensor(464.4688, grad_fn=<AddBackward0>)\n",
      "tensor(461.9648, grad_fn=<AddBackward0>)\n",
      "tensor(543.7950, grad_fn=<AddBackward0>)\n",
      "tensor(371.2940, grad_fn=<AddBackward0>)\n",
      "tensor(397.5436, grad_fn=<AddBackward0>)\n",
      "tensor(500.4864, grad_fn=<AddBackward0>)\n",
      "tensor(298.3153, grad_fn=<AddBackward0>)\n",
      "tensor(446.0081, grad_fn=<AddBackward0>)\n",
      "tensor(462.7547, grad_fn=<AddBackward0>)\n",
      "tensor(365.4286, grad_fn=<AddBackward0>)\n",
      "tensor(291.7990, grad_fn=<AddBackward0>)\n",
      "tensor(340.3470, grad_fn=<AddBackward0>)\n",
      "tensor(327.1719, grad_fn=<AddBackward0>)\n",
      "tensor(289.6020, grad_fn=<AddBackward0>)\n",
      "tensor(390.6011, grad_fn=<AddBackward0>)\n",
      "tensor(253.0230, grad_fn=<AddBackward0>)\n",
      "tensor(425.3330, grad_fn=<AddBackward0>)\n",
      "tensor(353.0468, grad_fn=<AddBackward0>)\n",
      "tensor(364.0410, grad_fn=<AddBackward0>)\n",
      "tensor(232.5634, grad_fn=<AddBackward0>)\n",
      "tensor(231.0079, grad_fn=<AddBackward0>)\n",
      "tensor(210.5089, grad_fn=<AddBackward0>)\n",
      "tensor(242.6437, grad_fn=<AddBackward0>)\n",
      "tensor(275.8011, grad_fn=<AddBackward0>)\n",
      "tensor(195.0102, grad_fn=<AddBackward0>)\n",
      "tensor(348.0797, grad_fn=<AddBackward0>)\n",
      "tensor(180.7986, grad_fn=<AddBackward0>)\n",
      "tensor(197.1019, grad_fn=<AddBackward0>)\n",
      "tensor(214.1360, grad_fn=<AddBackward0>)\n",
      "tensor(209.1630, grad_fn=<AddBackward0>)\n",
      "tensor(199.6253, grad_fn=<AddBackward0>)\n",
      "tensor(185.4848, grad_fn=<AddBackward0>)\n",
      "tensor(209.9603, grad_fn=<AddBackward0>)\n",
      "tensor(214.4605, grad_fn=<AddBackward0>)\n",
      "tensor(186.3818, grad_fn=<AddBackward0>)\n",
      "tensor(335.5060, grad_fn=<AddBackward0>)\n",
      "tensor(222.8786, grad_fn=<AddBackward0>)\n",
      "tensor(191.2897, grad_fn=<AddBackward0>)\n",
      "tensor(171.0892, grad_fn=<AddBackward0>)\n",
      "tensor(237.5063, grad_fn=<AddBackward0>)\n",
      "tensor(144.8646, grad_fn=<AddBackward0>)\n",
      "tensor(171.4214, grad_fn=<AddBackward0>)\n",
      "tensor(192.9226, grad_fn=<AddBackward0>)\n",
      "tensor(184.7697, grad_fn=<AddBackward0>)\n",
      "tensor(166.3520, grad_fn=<AddBackward0>)\n",
      "tensor(212.4897, grad_fn=<AddBackward0>)\n",
      "tensor(208.9915, grad_fn=<AddBackward0>)\n",
      "tensor(163.4097, grad_fn=<AddBackward0>)\n",
      "tensor(182.4442, grad_fn=<AddBackward0>)\n",
      "tensor(171.8882, grad_fn=<AddBackward0>)\n",
      "tensor(180.4317, grad_fn=<AddBackward0>)\n",
      "tensor(148.7204, grad_fn=<AddBackward0>)\n",
      "tensor(138.7957, grad_fn=<AddBackward0>)\n",
      "tensor(173.5787, grad_fn=<AddBackward0>)\n",
      "tensor(164.2174, grad_fn=<AddBackward0>)\n",
      "tensor(184.7396, grad_fn=<AddBackward0>)\n",
      "tensor(198.1505, grad_fn=<AddBackward0>)\n",
      "tensor(171.4707, grad_fn=<AddBackward0>)\n",
      "tensor(228.3598, grad_fn=<AddBackward0>)\n",
      "tensor(146.8051, grad_fn=<AddBackward0>)\n",
      "tensor(143.7547, grad_fn=<AddBackward0>)\n",
      "tensor(137.7458, grad_fn=<AddBackward0>)\n",
      "tensor(181.9935, grad_fn=<AddBackward0>)\n",
      "tensor(162.5332, grad_fn=<AddBackward0>)\n",
      "tensor(159.7023, grad_fn=<AddBackward0>)\n",
      "tensor(237.7957, grad_fn=<AddBackward0>)\n",
      "tensor(172.9769, grad_fn=<AddBackward0>)\n",
      "tensor(166.5507, grad_fn=<AddBackward0>)\n",
      "tensor(134.0380, grad_fn=<AddBackward0>)\n",
      "tensor(161.1401, grad_fn=<AddBackward0>)\n",
      "tensor(130.6249, grad_fn=<AddBackward0>)\n",
      "tensor(148.3929, grad_fn=<AddBackward0>)\n",
      "tensor(155.8976, grad_fn=<AddBackward0>)\n",
      "tensor(173.1655, grad_fn=<AddBackward0>)\n",
      "tensor(187.8810, grad_fn=<AddBackward0>)\n",
      "tensor(134.0834, grad_fn=<AddBackward0>)\n",
      "tensor(151.9964, grad_fn=<AddBackward0>)\n",
      "tensor(157.3691, grad_fn=<AddBackward0>)\n",
      "tensor(149.5518, grad_fn=<AddBackward0>)\n",
      "tensor(139.4180, grad_fn=<AddBackward0>)\n",
      "tensor(208.0811, grad_fn=<AddBackward0>)\n",
      "tensor(146.7669, grad_fn=<AddBackward0>)\n",
      "tensor(220.8301, grad_fn=<AddBackward0>)\n",
      "tensor(153.6220, grad_fn=<AddBackward0>)\n",
      "tensor(193.7764, grad_fn=<AddBackward0>)\n",
      "tensor(163.7657, grad_fn=<AddBackward0>)\n",
      "tensor(147.6548, grad_fn=<AddBackward0>)\n",
      "tensor(146.8951, grad_fn=<AddBackward0>)\n",
      "tensor(142.3736, grad_fn=<AddBackward0>)\n",
      "tensor(319.1008, grad_fn=<AddBackward0>)\n",
      "tensor(173.8735, grad_fn=<AddBackward0>)\n",
      "tensor(149.6236, grad_fn=<AddBackward0>)\n",
      "tensor(159.4750, grad_fn=<AddBackward0>)\n",
      "tensor(137.3434, grad_fn=<AddBackward0>)\n",
      "tensor(125.7078, grad_fn=<AddBackward0>)\n",
      "tensor(142.2423, grad_fn=<AddBackward0>)\n",
      "tensor(127.3261, grad_fn=<AddBackward0>)\n",
      "tensor(144.8279, grad_fn=<AddBackward0>)\n",
      "tensor(131.5432, grad_fn=<AddBackward0>)\n",
      "tensor(145.8373, grad_fn=<AddBackward0>)\n",
      "tensor(174.7339, grad_fn=<AddBackward0>)\n",
      "tensor(179.5815, grad_fn=<AddBackward0>)\n",
      "tensor(143.7674, grad_fn=<AddBackward0>)\n",
      "tensor(162.9948, grad_fn=<AddBackward0>)\n",
      "tensor(156.7960, grad_fn=<AddBackward0>)\n",
      "tensor(152.4724, grad_fn=<AddBackward0>)\n",
      "tensor(145.6439, grad_fn=<AddBackward0>)\n",
      "tensor(165.5849, grad_fn=<AddBackward0>)\n",
      "tensor(133.6887, grad_fn=<AddBackward0>)\n",
      "tensor(140.3791, grad_fn=<AddBackward0>)\n",
      "tensor(148.4261, grad_fn=<AddBackward0>)\n",
      "tensor(138.8510, grad_fn=<AddBackward0>)\n",
      "tensor(145.6906, grad_fn=<AddBackward0>)\n",
      "tensor(233.9327, grad_fn=<AddBackward0>)\n",
      "tensor(153.9230, grad_fn=<AddBackward0>)\n",
      "tensor(121.3597, grad_fn=<AddBackward0>)\n",
      "tensor(141.9749, grad_fn=<AddBackward0>)\n",
      "tensor(161.0599, grad_fn=<AddBackward0>)\n",
      "tensor(127.9281, grad_fn=<AddBackward0>)\n",
      "tensor(127.0461, grad_fn=<AddBackward0>)\n",
      "tensor(119.9146, grad_fn=<AddBackward0>)\n",
      "tensor(138.8896, grad_fn=<AddBackward0>)\n",
      "tensor(150.8677, grad_fn=<AddBackward0>)\n",
      "tensor(131.4632, grad_fn=<AddBackward0>)\n",
      "tensor(118.6025, grad_fn=<AddBackward0>)\n",
      "tensor(146.5620, grad_fn=<AddBackward0>)\n",
      "tensor(121.0750, grad_fn=<AddBackward0>)\n",
      "tensor(163.4147, grad_fn=<AddBackward0>)\n",
      "tensor(136.4331, grad_fn=<AddBackward0>)\n",
      "tensor(127.9503, grad_fn=<AddBackward0>)\n",
      "tensor(128.3111, grad_fn=<AddBackward0>)\n",
      "tensor(140.6577, grad_fn=<AddBackward0>)\n",
      "tensor(163.1447, grad_fn=<AddBackward0>)\n",
      "tensor(124.2349, grad_fn=<AddBackward0>)\n",
      "tensor(128.0138, grad_fn=<AddBackward0>)\n",
      "tensor(146.0611, grad_fn=<AddBackward0>)\n",
      "tensor(169.6785, grad_fn=<AddBackward0>)\n",
      "tensor(142.0746, grad_fn=<AddBackward0>)\n",
      "tensor(143.8726, grad_fn=<AddBackward0>)\n",
      "tensor(125.9116, grad_fn=<AddBackward0>)\n",
      "tensor(141.8488, grad_fn=<AddBackward0>)\n",
      "tensor(114.5445, grad_fn=<AddBackward0>)\n",
      "tensor(131.5134, grad_fn=<AddBackward0>)\n",
      "tensor(128.8619, grad_fn=<AddBackward0>)\n",
      "tensor(122.4183, grad_fn=<AddBackward0>)\n",
      "tensor(175.0323, grad_fn=<AddBackward0>)\n",
      "tensor(134.2047, grad_fn=<AddBackward0>)\n",
      "tensor(128.7404, grad_fn=<AddBackward0>)\n",
      "tensor(141.6402, grad_fn=<AddBackward0>)\n",
      "tensor(140.3344, grad_fn=<AddBackward0>)\n",
      "tensor(146.9538, grad_fn=<AddBackward0>)\n",
      "tensor(111.7078, grad_fn=<AddBackward0>)\n",
      "tensor(146.7872, grad_fn=<AddBackward0>)\n",
      "tensor(126.6149, grad_fn=<AddBackward0>)\n",
      "tensor(127.6867, grad_fn=<AddBackward0>)\n",
      "tensor(155.7501, grad_fn=<AddBackward0>)\n",
      "tensor(105.9311, grad_fn=<AddBackward0>)\n",
      "tensor(113.0779, grad_fn=<AddBackward0>)\n",
      "tensor(132.1952, grad_fn=<AddBackward0>)\n",
      "tensor(137.2451, grad_fn=<AddBackward0>)\n",
      "tensor(139.3379, grad_fn=<AddBackward0>)\n",
      "tensor(135.7518, grad_fn=<AddBackward0>)\n",
      "tensor(126.6446, grad_fn=<AddBackward0>)\n",
      "tensor(135.2417, grad_fn=<AddBackward0>)\n",
      "tensor(119.1290, grad_fn=<AddBackward0>)\n",
      "tensor(123.7151, grad_fn=<AddBackward0>)\n",
      "tensor(123.5255, grad_fn=<AddBackward0>)\n",
      "tensor(138.3564, grad_fn=<AddBackward0>)\n",
      "tensor(131.0983, grad_fn=<AddBackward0>)\n",
      "tensor(129.8753, grad_fn=<AddBackward0>)\n",
      "tensor(109.0077, grad_fn=<AddBackward0>)\n",
      "tensor(134.9044, grad_fn=<AddBackward0>)\n",
      "tensor(119.5280, grad_fn=<AddBackward0>)\n",
      "tensor(140.6658, grad_fn=<AddBackward0>)\n",
      "tensor(147.3716, grad_fn=<AddBackward0>)\n",
      "tensor(116.8903, grad_fn=<AddBackward0>)\n",
      "tensor(129.6812, grad_fn=<AddBackward0>)\n",
      "tensor(113.5202, grad_fn=<AddBackward0>)\n",
      "tensor(141.1048, grad_fn=<AddBackward0>)\n",
      "tensor(130.4131, grad_fn=<AddBackward0>)\n",
      "tensor(119.3545, grad_fn=<AddBackward0>)\n",
      "tensor(151.3360, grad_fn=<AddBackward0>)\n",
      "tensor(109.8450, grad_fn=<AddBackward0>)\n",
      "tensor(172.2752, grad_fn=<AddBackward0>)\n",
      "tensor(148.5209, grad_fn=<AddBackward0>)\n",
      "tensor(118.5581, grad_fn=<AddBackward0>)\n",
      "tensor(119.3115, grad_fn=<AddBackward0>)\n",
      "tensor(121.5599, grad_fn=<AddBackward0>)\n",
      "tensor(148.8667, grad_fn=<AddBackward0>)\n",
      "tensor(122.6834, grad_fn=<AddBackward0>)\n",
      "tensor(146.5426, grad_fn=<AddBackward0>)\n",
      "tensor(118.4057, grad_fn=<AddBackward0>)\n",
      "tensor(105.9312, grad_fn=<AddBackward0>)\n",
      "tensor(147.8875, grad_fn=<AddBackward0>)\n",
      "tensor(118.8335, grad_fn=<AddBackward0>)\n",
      "tensor(135.8882, grad_fn=<AddBackward0>)\n",
      "tensor(121.7028, grad_fn=<AddBackward0>)\n",
      "tensor(123.8675, grad_fn=<AddBackward0>)\n",
      "tensor(128.4001, grad_fn=<AddBackward0>)\n",
      "tensor(129.7541, grad_fn=<AddBackward0>)\n",
      "tensor(156.5064, grad_fn=<AddBackward0>)\n",
      "tensor(132.7731, grad_fn=<AddBackward0>)\n",
      "tensor(114.9663, grad_fn=<AddBackward0>)\n",
      "tensor(125.2158, grad_fn=<AddBackward0>)\n",
      "tensor(129.0848, grad_fn=<AddBackward0>)\n",
      "tensor(132.2654, grad_fn=<AddBackward0>)\n",
      "tensor(140.2273, grad_fn=<AddBackward0>)\n",
      "tensor(116.3892, grad_fn=<AddBackward0>)\n",
      "tensor(160.3841, grad_fn=<AddBackward0>)\n",
      "tensor(122.9125, grad_fn=<AddBackward0>)\n",
      "tensor(125.4225, grad_fn=<AddBackward0>)\n",
      "tensor(124.1360, grad_fn=<AddBackward0>)\n",
      "tensor(120.1918, grad_fn=<AddBackward0>)\n",
      "tensor(108.7646, grad_fn=<AddBackward0>)\n",
      "tensor(134.9999, grad_fn=<AddBackward0>)\n",
      "tensor(135.7350, grad_fn=<AddBackward0>)\n",
      "tensor(129.3174, grad_fn=<AddBackward0>)\n",
      "tensor(127.2722, grad_fn=<AddBackward0>)\n",
      "tensor(114.5391, grad_fn=<AddBackward0>)\n",
      "tensor(110.9541, grad_fn=<AddBackward0>)\n",
      "tensor(144.1837, grad_fn=<AddBackward0>)\n",
      "tensor(129.8130, grad_fn=<AddBackward0>)\n",
      "tensor(117.9112, grad_fn=<AddBackward0>)\n",
      "tensor(141.5061, grad_fn=<AddBackward0>)\n",
      "tensor(122.8497, grad_fn=<AddBackward0>)\n",
      "tensor(125.8309, grad_fn=<AddBackward0>)\n",
      "tensor(120.3967, grad_fn=<AddBackward0>)\n",
      "tensor(122.6588, grad_fn=<AddBackward0>)\n",
      "tensor(113.2101, grad_fn=<AddBackward0>)\n",
      "tensor(121.6783, grad_fn=<AddBackward0>)\n",
      "tensor(111.5114, grad_fn=<AddBackward0>)\n",
      "tensor(121.1978, grad_fn=<AddBackward0>)\n",
      "tensor(147.9219, grad_fn=<AddBackward0>)\n",
      "tensor(140.6910, grad_fn=<AddBackward0>)\n",
      "tensor(120.9217, grad_fn=<AddBackward0>)\n",
      "tensor(122.7131, grad_fn=<AddBackward0>)\n",
      "tensor(140.5466, grad_fn=<AddBackward0>)\n",
      "tensor(137.4756, grad_fn=<AddBackward0>)\n",
      "tensor(115.4788, grad_fn=<AddBackward0>)\n",
      "tensor(120.2883, grad_fn=<AddBackward0>)\n",
      "tensor(137.7970, grad_fn=<AddBackward0>)\n",
      "tensor(152.2301, grad_fn=<AddBackward0>)\n",
      "tensor(121.4030, grad_fn=<AddBackward0>)\n",
      "tensor(110.7731, grad_fn=<AddBackward0>)\n",
      "tensor(124.5038, grad_fn=<AddBackward0>)\n",
      "tensor(106.9419, grad_fn=<AddBackward0>)\n",
      "tensor(116.0124, grad_fn=<AddBackward0>)\n",
      "tensor(124.6067, grad_fn=<AddBackward0>)\n",
      "tensor(135.5605, grad_fn=<AddBackward0>)\n",
      "tensor(112.6602, grad_fn=<AddBackward0>)\n",
      "tensor(118.5339, grad_fn=<AddBackward0>)\n",
      "tensor(137.1290, grad_fn=<AddBackward0>)\n",
      "tensor(139.9672, grad_fn=<AddBackward0>)\n",
      "tensor(148.7846, grad_fn=<AddBackward0>)\n",
      "tensor(152.1737, grad_fn=<AddBackward0>)\n",
      "tensor(131.0763, grad_fn=<AddBackward0>)\n",
      "tensor(112.9086, grad_fn=<AddBackward0>)\n",
      "tensor(141.4063, grad_fn=<AddBackward0>)\n",
      "tensor(114.6507, grad_fn=<AddBackward0>)\n",
      "tensor(125.6247, grad_fn=<AddBackward0>)\n",
      "tensor(111.3771, grad_fn=<AddBackward0>)\n",
      "tensor(116.2107, grad_fn=<AddBackward0>)\n",
      "tensor(120.5743, grad_fn=<AddBackward0>)\n",
      "tensor(121.4032, grad_fn=<AddBackward0>)\n",
      "tensor(125.2001, grad_fn=<AddBackward0>)\n",
      "tensor(121.4791, grad_fn=<AddBackward0>)\n",
      "tensor(121.4302, grad_fn=<AddBackward0>)\n",
      "tensor(136.9109, grad_fn=<AddBackward0>)\n",
      "tensor(117.6311, grad_fn=<AddBackward0>)\n",
      "tensor(120.2927, grad_fn=<AddBackward0>)\n",
      "tensor(121.8555, grad_fn=<AddBackward0>)\n",
      "tensor(125.9205, grad_fn=<AddBackward0>)\n",
      "tensor(142.5805, grad_fn=<AddBackward0>)\n",
      "tensor(135.7669, grad_fn=<AddBackward0>)\n",
      "tensor(110.4086, grad_fn=<AddBackward0>)\n",
      "tensor(114.5035, grad_fn=<AddBackward0>)\n",
      "tensor(104.8137, grad_fn=<AddBackward0>)\n",
      "tensor(118.1714, grad_fn=<AddBackward0>)\n",
      "tensor(119.7443, grad_fn=<AddBackward0>)\n",
      "tensor(119.6321, grad_fn=<AddBackward0>)\n",
      "tensor(127.6870, grad_fn=<AddBackward0>)\n",
      "tensor(119.0163, grad_fn=<AddBackward0>)\n",
      "tensor(118.4075, grad_fn=<AddBackward0>)\n",
      "tensor(116.2332, grad_fn=<AddBackward0>)\n",
      "tensor(133.9408, grad_fn=<AddBackward0>)\n",
      "tensor(111.9052, grad_fn=<AddBackward0>)\n",
      "tensor(118.7985, grad_fn=<AddBackward0>)\n",
      "tensor(106.1014, grad_fn=<AddBackward0>)\n",
      "tensor(108.8040, grad_fn=<AddBackward0>)\n",
      "tensor(120.0970, grad_fn=<AddBackward0>)\n",
      "tensor(119.4773, grad_fn=<AddBackward0>)\n",
      "tensor(104.9455, grad_fn=<AddBackward0>)\n",
      "tensor(123.0959, grad_fn=<AddBackward0>)\n",
      "tensor(100.9445, grad_fn=<AddBackward0>)\n",
      "tensor(119.8891, grad_fn=<AddBackward0>)\n",
      "tensor(116.5725, grad_fn=<AddBackward0>)\n",
      "tensor(115.2705, grad_fn=<AddBackward0>)\n",
      "tensor(129.2254, grad_fn=<AddBackward0>)\n",
      "tensor(119.4733, grad_fn=<AddBackward0>)\n",
      "tensor(135.9865, grad_fn=<AddBackward0>)\n",
      "tensor(150.6181, grad_fn=<AddBackward0>)\n",
      "tensor(126.1240, grad_fn=<AddBackward0>)\n",
      "tensor(118.5354, grad_fn=<AddBackward0>)\n",
      "tensor(121.9434, grad_fn=<AddBackward0>)\n",
      "tensor(124.2100, grad_fn=<AddBackward0>)\n",
      "tensor(107.1664, grad_fn=<AddBackward0>)\n",
      "tensor(113.2642, grad_fn=<AddBackward0>)\n",
      "tensor(113.4825, grad_fn=<AddBackward0>)\n",
      "tensor(111.4758, grad_fn=<AddBackward0>)\n",
      "tensor(115.3949, grad_fn=<AddBackward0>)\n",
      "tensor(122.2813, grad_fn=<AddBackward0>)\n",
      "tensor(108.8178, grad_fn=<AddBackward0>)\n",
      "tensor(110.9169, grad_fn=<AddBackward0>)\n",
      "tensor(112.6356, grad_fn=<AddBackward0>)\n",
      "tensor(113.2948, grad_fn=<AddBackward0>)\n",
      "tensor(118.0866, grad_fn=<AddBackward0>)\n",
      "tensor(123.4896, grad_fn=<AddBackward0>)\n",
      "tensor(130.2459, grad_fn=<AddBackward0>)\n",
      "tensor(122.2184, grad_fn=<AddBackward0>)\n",
      "tensor(118.9705, grad_fn=<AddBackward0>)\n",
      "tensor(116.9784, grad_fn=<AddBackward0>)\n",
      "tensor(117.7497, grad_fn=<AddBackward0>)\n",
      "tensor(116.9320, grad_fn=<AddBackward0>)\n",
      "tensor(120.3777, grad_fn=<AddBackward0>)\n",
      "tensor(128.0651, grad_fn=<AddBackward0>)\n",
      "tensor(111.8011, grad_fn=<AddBackward0>)\n",
      "tensor(126.1276, grad_fn=<AddBackward0>)\n",
      "tensor(132.0276, grad_fn=<AddBackward0>)\n",
      "tensor(123.0524, grad_fn=<AddBackward0>)\n",
      "tensor(125.1088, grad_fn=<AddBackward0>)\n",
      "tensor(120.8114, grad_fn=<AddBackward0>)\n",
      "tensor(127.0352, grad_fn=<AddBackward0>)\n",
      "tensor(113.2048, grad_fn=<AddBackward0>)\n",
      "tensor(116.4402, grad_fn=<AddBackward0>)\n",
      "tensor(117.4491, grad_fn=<AddBackward0>)\n",
      "tensor(111.1846, grad_fn=<AddBackward0>)\n",
      "tensor(117.6276, grad_fn=<AddBackward0>)\n",
      "tensor(145.9039, grad_fn=<AddBackward0>)\n",
      "tensor(123.9897, grad_fn=<AddBackward0>)\n",
      "tensor(123.6774, grad_fn=<AddBackward0>)\n",
      "tensor(138.6718, grad_fn=<AddBackward0>)\n",
      "tensor(130.6229, grad_fn=<AddBackward0>)\n",
      "tensor(127.5638, grad_fn=<AddBackward0>)\n",
      "tensor(120.9881, grad_fn=<AddBackward0>)\n",
      "tensor(122.3348, grad_fn=<AddBackward0>)\n",
      "tensor(136.1447, grad_fn=<AddBackward0>)\n",
      "tensor(131.5711, grad_fn=<AddBackward0>)\n",
      "tensor(131.0694, grad_fn=<AddBackward0>)\n",
      "tensor(120.3036, grad_fn=<AddBackward0>)\n",
      "tensor(138.7694, grad_fn=<AddBackward0>)\n",
      "tensor(138.7673, grad_fn=<AddBackward0>)\n",
      "tensor(120.5753, grad_fn=<AddBackward0>)\n",
      "tensor(131.6096, grad_fn=<AddBackward0>)\n",
      "tensor(151.8603, grad_fn=<AddBackward0>)\n",
      "tensor(130.1209, grad_fn=<AddBackward0>)\n",
      "tensor(147.2127, grad_fn=<AddBackward0>)\n",
      "tensor(110.7944, grad_fn=<AddBackward0>)\n",
      "tensor(142.4821, grad_fn=<AddBackward0>)\n",
      "tensor(126.0139, grad_fn=<AddBackward0>)\n",
      "tensor(120.7592, grad_fn=<AddBackward0>)\n",
      "tensor(133.9559, grad_fn=<AddBackward0>)\n",
      "tensor(125.8911, grad_fn=<AddBackward0>)\n",
      "tensor(120.3257, grad_fn=<AddBackward0>)\n",
      "tensor(121.1856, grad_fn=<AddBackward0>)\n",
      "tensor(126.8610, grad_fn=<AddBackward0>)\n",
      "tensor(126.9735, grad_fn=<AddBackward0>)\n",
      "tensor(129.7643, grad_fn=<AddBackward0>)\n",
      "tensor(134.6300, grad_fn=<AddBackward0>)\n",
      "tensor(130.3927, grad_fn=<AddBackward0>)\n",
      "tensor(130.5527, grad_fn=<AddBackward0>)\n",
      "tensor(119.9028, grad_fn=<AddBackward0>)\n",
      "tensor(129.5231, grad_fn=<AddBackward0>)\n",
      "tensor(135.1089, grad_fn=<AddBackward0>)\n",
      "tensor(126.8782, grad_fn=<AddBackward0>)\n",
      "tensor(127.7230, grad_fn=<AddBackward0>)\n",
      "tensor(117.7813, grad_fn=<AddBackward0>)\n",
      "tensor(114.5501, grad_fn=<AddBackward0>)\n",
      "tensor(125.3116, grad_fn=<AddBackward0>)\n",
      "tensor(117.3256, grad_fn=<AddBackward0>)\n",
      "tensor(121.3480, grad_fn=<AddBackward0>)\n",
      "tensor(131.7615, grad_fn=<AddBackward0>)\n",
      "tensor(131.9949, grad_fn=<AddBackward0>)\n",
      "tensor(133.0415, grad_fn=<AddBackward0>)\n",
      "tensor(133.6649, grad_fn=<AddBackward0>)\n",
      "tensor(137.4728, grad_fn=<AddBackward0>)\n",
      "tensor(133.7330, grad_fn=<AddBackward0>)\n",
      "tensor(131.8848, grad_fn=<AddBackward0>)\n",
      "tensor(123.0225, grad_fn=<AddBackward0>)\n",
      "tensor(120.8716, grad_fn=<AddBackward0>)\n",
      "tensor(128.0102, grad_fn=<AddBackward0>)\n",
      "tensor(150.3154, grad_fn=<AddBackward0>)\n",
      "tensor(118.9573, grad_fn=<AddBackward0>)\n",
      "tensor(128.2930, grad_fn=<AddBackward0>)\n",
      "tensor(133.1450, grad_fn=<AddBackward0>)\n",
      "tensor(115.1749, grad_fn=<AddBackward0>)\n",
      "tensor(128.2980, grad_fn=<AddBackward0>)\n",
      "tensor(133.2555, grad_fn=<AddBackward0>)\n",
      "tensor(131.8500, grad_fn=<AddBackward0>)\n",
      "tensor(131.3546, grad_fn=<AddBackward0>)\n",
      "tensor(122.2033, grad_fn=<AddBackward0>)\n",
      "tensor(128.9538, grad_fn=<AddBackward0>)\n",
      "tensor(120.6829, grad_fn=<AddBackward0>)\n",
      "tensor(129.5152, grad_fn=<AddBackward0>)\n",
      "tensor(131.5576, grad_fn=<AddBackward0>)\n",
      "tensor(117.1775, grad_fn=<AddBackward0>)\n",
      "tensor(125.8032, grad_fn=<AddBackward0>)\n",
      "tensor(111.6424, grad_fn=<AddBackward0>)\n",
      "tensor(140.2785, grad_fn=<AddBackward0>)\n",
      "tensor(116.1767, grad_fn=<AddBackward0>)\n",
      "tensor(109.6001, grad_fn=<AddBackward0>)\n",
      "tensor(121.9666, grad_fn=<AddBackward0>)\n",
      "tensor(112.2932, grad_fn=<AddBackward0>)\n",
      "tensor(113.2835, grad_fn=<AddBackward0>)\n",
      "tensor(128.5700, grad_fn=<AddBackward0>)\n",
      "tensor(127.2023, grad_fn=<AddBackward0>)\n",
      "tensor(117.0039, grad_fn=<AddBackward0>)\n",
      "tensor(110.0046, grad_fn=<AddBackward0>)\n",
      "tensor(120.6232, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_loop(net, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"Saves/L_50k.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_load import get_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_train_dataset(10_000)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, 1000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,) in dataloader:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      " \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mT_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mworker_init_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmultiprocessing_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprefetch_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpersistent_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      "the given dataset.\n",
      "\n",
      "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "iterable-style datasets with single- or multi-process loading, customizing\n",
      "loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): dataset from which to load the data.\n",
      "    batch_size (int, optional): how many samples per batch to load\n",
      "        (default: ``1``).\n",
      "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "        at every epoch (default: ``False``).\n",
      "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "        returns a batch of indices at a time. Mutually exclusive with\n",
      "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "        and :attr:`drop_last`.\n",
      "    num_workers (int, optional): how many subprocesses to use for data\n",
      "        loading. ``0`` means that the data will be loaded in the main process.\n",
      "        (default: ``0``)\n",
      "    collate_fn (Callable, optional): merges a list of samples to form a\n",
      "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "        map-style dataset.\n",
      "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "        into device/CUDA pinned memory before returning them.  If your data elements\n",
      "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "        see the example below.\n",
      "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "        the size of dataset is not divisible by the batch size, then the last batch\n",
      "        will be smaller. (default: ``False``)\n",
      "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "        from workers. Should always be non-negative. (default: ``0``)\n",
      "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "        input, after seeding and before data loading. (default: ``None``)\n",
      "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
      "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
      "        be used. (default: ``None``)\n",
      "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "        ``base_seed`` for workers. (default: ``None``)\n",
      "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      "        in advance by each worker. ``2`` means there will be a total of\n",
      "        2 * num_workers batches prefetched across all workers. (default value depends\n",
      "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      "        Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
      "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
      "        the worker processes after a dataset has been consumed once. This allows to\n",
      "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
      "        ``True``.\n",
      "\n",
      "\n",
      ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "             cannot be an unpicklable object, e.g., a lambda function. See\n",
      "             :ref:`multiprocessing-best-practices` on more details related\n",
      "             to multiprocessing in PyTorch.\n",
      "\n",
      ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "             loading to avoid duplicate data.\n",
      "\n",
      "             However, if sharding results in multiple workers having incomplete last batches,\n",
      "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "             cases in general.\n",
      "\n",
      "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "             `Multi-process data loading`_.\n",
      "\n",
      ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "\n",
      ".. _multiprocessing context:\n",
      "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/torch-cpu/lib/python3.11/site-packages/torch/utils/data/dataloader.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     DataLoader, NodeLoader, LinkLoader, ClusterLoader, GraphSAINTSampler, ShaDowKHopSampler, RandomNodeLoader, ZipLoader, DataListLoader, DenseDataLoader, ..."
     ]
    }
   ],
   "source": [
    "? torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, mask = to_dense_batch(G, lengs, fill_value=0, max_num_nodes=1000)\n",
    "A = to_dense_adj(E, lengs, max_num_nodes=1000) # (batch, 1000, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1000, 3]), torch.Size([2, 1000, 1000]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X\n",
    "A = A\n",
    "X.shape, A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphVAE(\n",
       "  (sage): ModuleList(\n",
       "    (0): DenseSAGEConv(3, 16)\n",
       "    (1): DenseSAGEConv(16, 16)\n",
       "    (2): DenseSAGEConv(16, 3)\n",
       "  )\n",
       "  (drop): ModuleList(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Dropout(p=0.4, inplace=False)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (batch_norm): ModuleList(\n",
       "    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pool): ModuleList(\n",
       "    (0): MinCut_Pool(\n",
       "      (linear): Linear(in_features=16, out_features=500, bias=True)\n",
       "    )\n",
       "    (1): MinCut_Pool(\n",
       "      (linear): Linear(in_features=16, out_features=250, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (tr_mu): Linear(in_features=3, out_features=16, bias=True)\n",
       "  (tr_var): Linear(in_features=3, out_features=16, bias=True)\n",
       "  (tr_rev): Linear(in_features=16, out_features=3, bias=True)\n",
       "  (revsage): ModuleList(\n",
       "    (0): DenseSAGEConv(16, 3)\n",
       "    (1): DenseSAGEConv(16, 16)\n",
       "    (2): DenseSAGEConv(3, 16)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = GraphVAE(3, 16, 3)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, A, mu, logvar, L1, L2 = net(X, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1000, 3]), torch.Size([2, 1000, 1000]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape, A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
