#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine biblatex
\cite_engine_type authoryear
\biblatex_bibstyle numeric
\biblatex_citestyle numeric
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\backgroundcolor #000000
\fontcolor #ffffff
\notefontcolor #686868
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Graph Variational neural network for fast end to end detector simulation
\end_layout

\begin_layout Author
Dinesh PR
\end_layout

\begin_layout Standard
towards partial fulfillment of course requirements for PH 561 (Fall 2023)
 at the University of Alabama
\end_layout

\begin_layout Section
Introduction and Background
\end_layout

\begin_layout Standard
In the current work, we build and study a generative model based on graph
 variational autoencoders to accelerate simulations of boosted top quark
 production in the Large Hadron Collider (LHC)
\begin_inset CommandInset citation
LatexCommand cite
key "LHC"
literal "false"

\end_inset

.
 While it trains on dataset obtained from existing Monte Carlo-based generation
 and detector simulation models, we aim to accelerate re-sampling the same
 without compromising on the accuracy and fidelity.
 A successful implementation of the model can be used to program customized
 FPGA-based triggers that can avoid pile-up of unnecessary background hits
 during collision experiments at the LHC.
\end_layout

\begin_layout Subsection
CMS detector and collision 
\begin_inset Quotes eld
\end_inset

images
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
The CMS detector
\begin_inset CommandInset citation
LatexCommand cite
key "CMS_Exp"
literal "false"

\end_inset

 in the LHC is arranged in cylindrical sections of different types of subdetecto
rs (see fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:CMS_figure"

\end_inset

), with the central axis along the line of collision between proton beams.
 This includes both barrel and endcap (see figure) sections of each subdetector.
 We look at 3 particular subdetectors as relevant to this study- the inner
 tracking system (Tracker), the electromagnetic calorimeter (ECAL) and the
 hadronic calorimeter (HCAL)
\begin_inset CommandInset citation
LatexCommand cite
key "e2e_classification"
literal "false"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/cms_detector.png
	scale 3

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:CMS_figure"

\end_inset

Schematics of the CMS detector at LHC, CERN.
 Source: 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://cms.cern/detector
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Tracker is the innermost series of finely segmented silicon wafers that
 (non-destructively) detect positional tracks left by particles formed from
 a collision beam, deciphering practically nothing about their energies.
 The 
\begin_inset Quotes eld
\end_inset

pixels
\begin_inset Quotes erd
\end_inset

 in the Tracker are labelled using 
\begin_inset Formula $\left(z,\phi\right)$
\end_inset

 and 
\begin_inset Formula $\left(\rho,\phi\right)$
\end_inset

 for the barrel and endcap sections respectively- where 
\begin_inset Formula $z$
\end_inset

 denotes length along the axis, 
\begin_inset Formula $\rho$
\end_inset

 denotes the perpendicular radius and 
\begin_inset Formula $\phi$
\end_inset

 denotes the azimuthal angle.
\end_layout

\begin_layout Standard
Surrounding the Tracker is the ECAL subdetector which captures the incoming
 photons and electrons, and measures their energies using scintillating
 lead tungstate crystals.
 In the barrel section, it is segmented by pseudorapidity 
\begin_inset Formula $\left(i\eta_{EB}\right)$
\end_inset

 and azimuthal angle 
\begin_inset Formula $\left(i\phi_{EB}\right)$
\end_inset

 and spans within 
\begin_inset Formula $\left|\eta\right|<1.479$
\end_inset

 making it a 
\begin_inset Formula $170\times360$
\end_inset

 grid of 
\begin_inset Quotes eld
\end_inset

pixels
\begin_inset Quotes erd
\end_inset

.
 The endcap is labelled using 
\begin_inset Formula $\left(iX,iY\right)$
\end_inset

 as a Cartesian grid of pixels arranged in a circle.
 Psudorapidity is an alternative to the polar angle 
\begin_inset Formula $\left(\theta\right)$
\end_inset

 frequently used in spherical coordinates and they're related by:
\begin_inset Formula 
\[
\eta=-\ln\left[\tan\frac{\theta}{2}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
The HCAL subdetector encloses the ECAL and measures the energies of hadronic
 particles (mostly charged pions and kaons) using scintillating brass towers.
 The barrel section encloses the pseudorapidity range 
\begin_inset Formula $\left|\eta\right|<3$
\end_inset

.
 The pixels in the barrel section of HCAL produce an image that's more coarsely
 segmented with roughly 
\begin_inset Formula $1$
\end_inset

 HCAL pixel per 
\begin_inset Formula $5$
\end_inset

 ECAL pixels along both the 
\begin_inset Formula $i\phi$
\end_inset

 and 
\begin_inset Formula $i\eta$
\end_inset

 directions.
 
\end_layout

\begin_layout Subsection
Event generation for the Large Hadrom Collider
\end_layout

\begin_layout Standard
Quantum field theory
\begin_inset CommandInset citation
LatexCommand cite
key "zee_qft,weinberg_QFT,peskin_QFT"
literal "false"

\end_inset

 is the mathematical framework based on which theoretical as well as numerical
 computations of physical quantities observed in high energy experiments
 are performed.
 In particular, the values of Green's functions or S matrices determine
 the various scattering 
\emph on
cross sections
\emph default
 for the final states of particles observed in different detectors.
 The simulation pipeline can be divided into several steps
\begin_inset CommandInset citation
LatexCommand cite
key "event_generation_hep_review"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Hard scattering
\end_layout

\begin_layout Standard
The 
\emph on
hard scattering
\emph default
 component probes the smallest length scales around the collision center.
 The cross sections are usually determined using ab inito (first principle),
 perturbative QFT calculations at the highest order of accuracy feasible
 in terms of the coupling constants.
 Terms of the perturbation series can be represented visually using Feynman
 diagrams
\begin_inset CommandInset citation
LatexCommand cite
key "feynman_papers"
literal "false"

\end_inset

 and their values are often plagued by problems with IR divergences in loop
 integrals which often cancel analytically with tree-level counterparts.
 If analytic solutions are not available, Monte Carlo-based simulations
\begin_inset CommandInset citation
LatexCommand cite
key "Hard_scattering_MC_1,Hard_scattering_MC_2,Hard_scattering_MC_3"
literal "false"

\end_inset

 are used for which there are ever-increasing quests for improvements in
 efficiency and numerical stability.
\end_layout

\begin_layout Paragraph
Secondary interactions and decays
\end_layout

\begin_layout Standard
Since detectors are present at much larger distances from the center, there
 can be additional collisions and decays beyond the hard scattering which
 need to simulated accurately.
 Factorization theorems
\begin_inset CommandInset citation
LatexCommand cite
key "Factorization_1,Factorization_2"
literal "false"

\end_inset

 give rise to correlations between the momenta of partonic (quarks/gluons)
 currents of different flavours, which are encoded semi-classically as integrals
 of parton distribution functions (PDF).
 Their time-evolution is modelled using Monte Carlo-based algorithms like
 parton showers 
\begin_inset CommandInset citation
LatexCommand cite
key "parton_showers"
literal "false"

\end_inset

and dipole showers
\begin_inset CommandInset citation
LatexCommand cite
key "dipole_showers"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Numerical libraries and open simulated datasets
\end_layout

\begin_layout Standard
Many generic software libraries that simulate parts of the event generation
 chain we briefly summarized are available.
 Most popular general-purpose packages available for the same include SHERPA
\begin_inset CommandInset citation
LatexCommand cite
key "SHERPA"
literal "false"

\end_inset

, HERWIG
\begin_inset CommandInset citation
LatexCommand cite
key "HERWIG"
literal "false"

\end_inset

 and PYTHIA
\begin_inset CommandInset citation
LatexCommand cite
key "PYTHIA"
literal "false"

\end_inset

.
 They're run in combination with software that simulate the behavior of
 particular detectors (in say, CMS) like GEANT
\begin_inset CommandInset citation
LatexCommand cite
key "GEANT4"
literal "false"

\end_inset

.
 While the Monte Carlo-based generators are highly accurate, they often
 scale poorly with the collision energy, luminosity and detector count.
 Faster detector simulation libraries like DELPHES
\begin_inset CommandInset citation
LatexCommand cite
key "DELPHES"
literal "false"

\end_inset

 tend to make approximations that trade off accuracy for speed.
 Full simulation of collider experiments using theory-driven collision event
 generators and experimentally optimized detector simulators is referred
 to as end-to-end event generation.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Find as many primary research articles for the concepts outlined here, as
 well as standard texts.
\end_layout

\end_inset

 
\end_layout

\begin_layout Subsection
Generative machine learning and Graph variational autoencoders
\end_layout

\begin_layout Standard
Generative networks
\begin_inset CommandInset citation
LatexCommand cite
key "Generative_NN_survey"
literal "false"

\end_inset

 are machine learning tools used to sample from a learned data distribution
 from the training set.
 While Monte Carlo generators asymptotically (in the limit of infinite samples)
 converge to the actual distribution for averaged quantities, they can suffer
 from large autocorrelations between successive samples and poor accuracies
 for non-averaged quantities for practically finite number of samples
\begin_inset CommandInset citation
LatexCommand cite
key "metropolis_mcmc"
literal "false"

\end_inset

.
 On the other hand, most generative ML models sample with no autocorrelations
 but their asymptotic closeness to the target distribution depends on the
 model architecture, training parameters, loss function and the quality
 of training data.
 Most popular classes of generative networks include variational autoencoders
\begin_inset CommandInset citation
LatexCommand cite
key "VAEs"
literal "false"

\end_inset

 (VAE), generative adversarial networks
\begin_inset CommandInset citation
LatexCommand cite
key "GANs"
literal "false"

\end_inset

 (GAN) and normalizing flows (NF)
\begin_inset CommandInset citation
LatexCommand cite
key "Normalizing_flows"
literal "false"

\end_inset

.
 VAEs and GANs generally offer highly expressive models and have already
 been used in many high energy physics applications including end to end
 event generation
\begin_inset CommandInset citation
LatexCommand cite
key "ML_LHC_events_review"
literal "false"

\end_inset

.
 NFs are known to be less expressive but allow us to explicitly compute
 likelihoods of different samples and can be inverted for reverse simulations,
 which have been exploited in many HEP applications.
\end_layout

\begin_layout Paragraph
Variational autoencoders
\end_layout

\begin_layout Standard
VAEs use neural networks to 
\emph on
encode
\emph default
 or compress high dimensional input data to lower dimensional latent space
 which is also the parameter space for an easily sampled probability distributio
n (like Gaussian) and these samples are then 
\emph on
decoded
\emph default
 by other neural networks back to the original input space.
 They are typically trained to minimize a distance between the input and
 the (decoded) output data, like mean squared error (MSE), along with a
 prior likelihood term into an evidence lower bound (ELBO) estimator.
 In our work, we use graph-based neural networks for encoders and decoders
 in a VAE, an idea which has already been explored
\begin_inset CommandInset citation
LatexCommand cite
key "GraphVAE_simulation"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Graph convolution and pooling operations
\end_layout

\begin_layout Standard
In the geometric deep learning framework
\begin_inset CommandInset citation
LatexCommand cite
key "bronstein2017geometric"
literal "false"

\end_inset

, we tend to use operations that preserve the structure and symmetries of
 the input data.
 In the case of graph data, we'd like to preserve the neighborhood of each
 node and require that the output be invariant to permutations within the
 neighborhoods.
 Spectral convolutions
\begin_inset CommandInset citation
LatexCommand cite
key "Spectral_GNN"
literal "false"

\end_inset

 were initially developed as compatible operations on graph data but they
 tend to scale poorly with the number of nodes and edges.
 Message passing layers like GCN 
\begin_inset CommandInset citation
LatexCommand cite
key "Semi-supervised_GCN"
literal "false"

\end_inset

and SAGE
\begin_inset CommandInset citation
LatexCommand cite
key "Graph_SAGE"
literal "false"

\end_inset

 were developed to compute convolutions in polynomial time on the size of
 input data.
 We convert the sparse detector image by taking the non-zero pixels as nodes
 and putting edges between 
\emph on
k 
\emph default
nearest neighbors (knn) of every node.
 We use SAGE convolution layers, which is ideal for aggregating information
 from the neighborhood of every node when the edge count 
\begin_inset Formula $\left(\sim k\right)$
\end_inset

is very small.
 The operation is mathematically described using
\begin_inset Formula 
\[
\bm{x}'_{i}=\bm{W}_{1}\bm{x}_{i}+\bm{W}_{2}.\text{agg}_{j\in\mathcal{N}(i)}\bm{x}_{j}
\]

\end_inset

where 
\begin_inset Formula $\bm{W}_{1}$
\end_inset

 and 
\begin_inset Formula $\bm{W}_{2}$
\end_inset

 are weights of the layer (which are optimized during training) and 'agg'
 is an aggregating operation like mean or max.
\end_layout

\begin_layout Section
Data and Pre-processing
\end_layout

\begin_layout Standard
In this work, we focus on the quark-gluon shower dataset for the CMS detector,
 available on the CERN open data portal
\begin_inset CommandInset citation
LatexCommand cite
key "CERN_Open_data_portal"
literal "false"

\end_inset

 where the event generation of stable particle arriving at the detectors
 were done using PYTHIA.
 GEANT4 is used for detector simulation, digitization, image generation
 and reconstruction.
 It contains 
\begin_inset Formula $125\times125$
\end_inset

 images corresponding to the Tracker, ECAL and HCAL subdetector, labelled
 
\begin_inset Formula $0$
\end_inset

 for quark jet and 
\begin_inset Formula $1$
\end_inset

 for gluon jet responses.
 Out of roughly 130K images (equally split between quark and gluon jets),
 we train a GraphVAE quark jet ECAL images alone, for simplicity as well
 as benchmarking the model against corresponding images of gluon jets- investiga
ting the utility of GraphVAE for detecting anomalies in input data.
 To convert the images to 
\emph on
graph
\emph default
 format, we pool all the hits with energies greater that 
\begin_inset Formula $10^{-3}$
\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
An upper bound of 400 hits was chosen, sorted according to energy in descending
 order
\end_layout

\end_inset

compress them to form 3-feature nodes (pixel positions and energies).
 This considerably reduces the size of the dataset file in the computer's
 memory- from 
\begin_inset Formula $\approx600$
\end_inset

 Mb to 
\begin_inset Formula $\approx100$
\end_inset

 Mb, in the HDF5 dataset format.
 The positions and energies are further normalized to values in the 
\begin_inset Formula $(0,1)$
\end_inset

 interval to finally prepare the training dataset.
 Training and test datasets consist 50,000 and 10,000 of the graph-formatted
 ECAL images respectively.
 We compiled another test dataset of 10,000 gluon images for benchmarking.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
Pytorch deep learning framework coupled with Pytorch geometric library (which
 specializes in operations on graphs) were used to implement the GraphVAE
 model used in this work.
 The encoder network consists of 3 SAGE convolution layer with 2 MinCut
 Pool layers sandwiched in between, gradually reducing the dimensionality
 of the latent space to 20 from the input space dimensionality of 400.
 The decoder network exactly mirrors this operation with similar graph operation
s that upscale the dimensions back to 400.
 Degree normalization is applied to the adjacency matrix between every upscaling
/downscaling operation and masking out padded nodes has been carefully applied
 to ensure there are no 
\begin_inset Quotes eld
\end_inset

leaks
\begin_inset Quotes erd
\end_inset

 in the graph operations.
 Since this is a toy model, fairly modest layer widths of upto 64 were used
 and it remains to be seen how scaling to bigger neural networks affects
 the results.
 
\end_layout

\begin_layout Standard
Mean squared error (MSE) loss between the input and output features (both
 hits and their energies) were used along with a KL-divergence loss for
 the reparameterization mean and variance, as well as a regularization term
 for optimizing cluster assignments while downscaling/upscaling.
 ADAM optimizer has been used to update weights via gradient descent during
 training with a learning rate of 
\begin_inset Formula $10^{-3}$
\end_inset

.
 A publicly accessible codebase of our model can be found here: 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

github.com/dinesh110598/Quark_Gluon_Data/main
\end_layout

\end_inset

 and all data/figures in this work are reproducible.
\end_layout

\begin_layout Subsection
Cylindrical geometry of image data
\end_layout

\begin_layout Standard
Assigning the position features values between 
\begin_inset Formula $0$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

 imposes a 
\begin_inset Quotes eld
\end_inset

flat
\begin_inset Quotes erd
\end_inset

 or 
\emph on
Cartesian
\emph default
 geometry for the detector hit images, while the 
\begin_inset Formula $i\phi$
\end_inset

 direction horizontal to the images is circular or periodic which can lead
 to loss of information at the ends near 
\begin_inset Formula $\phi=0,2\pi$
\end_inset

 during training.
 To take this periodic nature into account, we translate the 
\begin_inset Formula $x$
\end_inset

 coordinates of some hits by 
\begin_inset Formula $\pm1$
\end_inset

 depending on the position of predicted hit positions
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The train.py file in our code repository contains a precise implementation
\end_layout

\end_inset

.
 So we train our model using both a naive flat geometry loss and a periodic
 one to compare their MSE metrics on both training and test datasets in
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:MSE_metrics"

\end_inset

.
 Training using periodic geometry clearly outperforms the flat geometry
 counterpart of the Graph VAE model in the given metric across different
 datasets as well as for both hit positions and the corresponding energies.
 Figure compares the true and reconstructed 
\begin_inset Quotes eld
\end_inset

images
\begin_inset Quotes erd
\end_inset

 of randomly chosen samples from each dataset.
 It's generally hard to visually determine the performance of the flat model
 against the periodic one from looking through the plots.
 
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dataset (model)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hit MSE
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Energy MSE
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Quark training (flat)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.4043
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0013
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Quark training (periodic)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0917
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0004
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Quark test (flat)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.3786
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0013
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Quark test (periodic)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0864
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0004
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gluon test (flat)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.4144
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0014
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gluon test (periodic)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0942
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0005
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:MSE_metrics"

\end_inset

 This table describes the Mean Square Error (MSE) metric of hit and energy
 reconstruction by models trained on flat/periodic geometries on different
 datasets (lower values are better)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Gluon data as anomalies
\end_layout

\begin_layout Standard
An earlier work demonstrates classifying images of quark and gluon jets
 using convolutional neural networks where the ML model trains to discriminate
 between different labels.
 In the current work, we attempt to train a variational autoencoder to reconstru
ct samples of quark jets alone, so it has no prior information about gluon
 jet samples.
 Hence, we expect the model to perform worse in terms of various metrics
 when queried to reconstruct gluon jets, compared to quark jets and thus
 be treated as anomalies beyond a threshold value of these metrics.
 Referring to table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:MSE_metrics"

\end_inset

 seems to indicate similar metrics for both flat and periodic trained Graph
 VAE models for quark and gluon jets.
 In a closer look, training dataset has worse MSE metric compared to the
 gluon test dataset, which are in turn marginally higher than the quark
 test dataset for both hits and energies.
 Visual comparisons using figure offers no insight either.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Plots/Flat_quark_train.pdf
	scale 25

\end_inset


\begin_inset Graphics
	filename Plots/Periodic_quark_train.pdf
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Plots/Flat_quark_val.pdf
	scale 25

\end_inset


\begin_inset Graphics
	filename Plots/periodic_quark_val.pdf
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Plots/Flat_gluon_val.pdf
	scale 25

\end_inset


\begin_inset Graphics
	filename Plots/periodic_gluon_val.pdf
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Img_reconstructions"

\end_inset

Original and reconstructed samples from different datasets are plotted side-by-s
ide presented in the same (row wise) order as table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:MSE_metrics"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
<WIP>
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "ref"

\end_inset


\end_layout

\end_body
\end_document
