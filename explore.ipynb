{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric import nn as gnn\n",
    "\n",
    "from graph_vae import GraphVAE\n",
    "from train import train_loop2\n",
    "from data_load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "d = torch.randn(10)\n",
    "d_diag = torch.diag_embed(d)\n",
    "M = torch.randn(10, 10)\n",
    "\n",
    "print(torch.all(d.unsqueeze(1)*M == torch.matmul(d_diag, M)))\n",
    "print(torch.all(M * d == torch.matmul(M, d_diag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_train_dataset()\n",
    "data_loader = torch.utils.data.DataLoader(dataset, 200, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8951)\n",
      "tensor(0.9118)\n",
      "tensor(0.9004)\n",
      "tensor(0.8894)\n",
      "tensor(0.8476)\n",
      "tensor(0.9631)\n",
      "tensor(0.8371)\n",
      "tensor(1.0133)\n",
      "tensor(0.8952)\n",
      "tensor(0.9213)\n",
      "tensor(0.8329)\n",
      "tensor(0.8558)\n",
      "tensor(0.9442)\n",
      "tensor(0.8626)\n",
      "tensor(0.8884)\n",
      "tensor(0.9379)\n",
      "tensor(0.8939)\n",
      "tensor(0.8558)\n",
      "tensor(1.1926)\n",
      "tensor(0.9205)\n",
      "tensor(0.9311)\n",
      "tensor(0.8475)\n",
      "tensor(0.9733)\n",
      "tensor(1.0340)\n",
      "tensor(0.8867)\n",
      "tensor(0.8736)\n",
      "tensor(0.8699)\n",
      "tensor(0.9059)\n",
      "tensor(0.9021)\n",
      "tensor(0.8803)\n",
      "tensor(0.8987)\n",
      "tensor(0.9044)\n",
      "tensor(1.0155)\n",
      "tensor(0.9302)\n",
      "tensor(0.9912)\n",
      "tensor(1.0871)\n",
      "tensor(0.9920)\n",
      "tensor(0.9254)\n",
      "tensor(0.9718)\n",
      "tensor(0.9681)\n",
      "tensor(0.9595)\n",
      "tensor(0.9228)\n",
      "tensor(0.8817)\n",
      "tensor(0.8920)\n",
      "tensor(0.9043)\n",
      "tensor(1.0227)\n",
      "tensor(0.9477)\n",
      "tensor(0.8980)\n",
      "tensor(1.2631)\n",
      "tensor(0.9206)\n",
      "tensor(0.8822)\n",
      "tensor(0.8873)\n",
      "tensor(0.8166)\n",
      "tensor(0.8116)\n",
      "tensor(0.9536)\n",
      "tensor(1.2312)\n",
      "tensor(0.8409)\n",
      "tensor(0.9117)\n",
      "tensor(0.8505)\n",
      "tensor(0.9070)\n",
      "tensor(0.9140)\n",
      "tensor(0.8872)\n",
      "tensor(0.8432)\n",
      "tensor(0.9075)\n",
      "tensor(0.9113)\n",
      "tensor(0.8508)\n",
      "tensor(1.0221)\n",
      "tensor(0.8749)\n",
      "tensor(1.0153)\n",
      "tensor(0.8700)\n",
      "tensor(0.9395)\n",
      "tensor(0.8875)\n",
      "tensor(0.8758)\n",
      "tensor(0.9563)\n",
      "tensor(0.9622)\n",
      "tensor(0.9016)\n",
      "tensor(0.8822)\n",
      "tensor(0.8075)\n",
      "tensor(0.9127)\n",
      "tensor(0.9923)\n",
      "tensor(0.8153)\n",
      "tensor(0.9186)\n",
      "tensor(0.9276)\n",
      "tensor(0.9409)\n",
      "tensor(0.9684)\n",
      "tensor(0.9285)\n",
      "tensor(0.8307)\n",
      "tensor(0.9584)\n",
      "tensor(1.2779)\n",
      "tensor(1.0155)\n",
      "tensor(0.9690)\n",
      "tensor(0.9660)\n",
      "tensor(0.9169)\n",
      "tensor(0.8799)\n",
      "tensor(0.9015)\n",
      "tensor(0.9541)\n",
      "tensor(0.9859)\n",
      "tensor(0.9733)\n",
      "tensor(0.9041)\n",
      "tensor(0.8115)\n",
      "tensor(0.9000)\n",
      "tensor(0.8998)\n",
      "tensor(0.9141)\n",
      "tensor(0.9143)\n",
      "tensor(0.9195)\n",
      "tensor(0.8959)\n",
      "tensor(0.8197)\n",
      "tensor(0.8970)\n",
      "tensor(0.8833)\n",
      "tensor(0.9090)\n",
      "tensor(1.2498)\n",
      "tensor(0.9213)\n",
      "tensor(0.8579)\n",
      "tensor(0.9881)\n",
      "tensor(1.1530)\n",
      "tensor(0.9677)\n",
      "tensor(0.8657)\n",
      "tensor(0.8813)\n",
      "tensor(0.8738)\n",
      "tensor(0.8665)\n",
      "tensor(0.8671)\n",
      "tensor(0.8610)\n",
      "tensor(0.8925)\n",
      "tensor(0.9770)\n",
      "tensor(0.8606)\n",
      "tensor(0.8683)\n",
      "tensor(0.9006)\n",
      "tensor(0.8661)\n",
      "tensor(0.9673)\n",
      "tensor(0.9438)\n",
      "tensor(0.8961)\n",
      "tensor(0.9181)\n",
      "tensor(0.9837)\n",
      "tensor(0.9114)\n",
      "tensor(0.9291)\n",
      "tensor(0.8835)\n",
      "tensor(0.9046)\n",
      "tensor(1.0555)\n",
      "tensor(0.8198)\n",
      "tensor(0.8658)\n",
      "tensor(0.8691)\n",
      "tensor(1.0092)\n",
      "tensor(0.8549)\n",
      "tensor(1.2349)\n",
      "tensor(0.9248)\n",
      "tensor(0.9233)\n",
      "tensor(0.8795)\n",
      "tensor(0.9675)\n",
      "tensor(0.9012)\n",
      "tensor(0.9161)\n",
      "tensor(0.9127)\n",
      "tensor(0.8269)\n",
      "tensor(0.8555)\n",
      "tensor(1.0798)\n",
      "tensor(0.8814)\n",
      "tensor(0.9038)\n",
      "tensor(1.0110)\n",
      "tensor(0.9713)\n",
      "tensor(0.8990)\n",
      "tensor(0.9193)\n",
      "tensor(0.8136)\n",
      "tensor(0.9294)\n",
      "tensor(0.9789)\n",
      "tensor(0.8933)\n",
      "tensor(0.9300)\n",
      "tensor(0.8555)\n",
      "tensor(0.8862)\n",
      "tensor(1.2067)\n",
      "tensor(0.8851)\n",
      "tensor(0.8871)\n",
      "tensor(0.8559)\n",
      "tensor(0.8550)\n",
      "tensor(0.8931)\n",
      "tensor(1.0137)\n",
      "tensor(0.9091)\n",
      "tensor(0.8945)\n",
      "tensor(0.9244)\n",
      "tensor(0.8740)\n",
      "tensor(0.8591)\n",
      "tensor(0.8517)\n",
      "tensor(1.0278)\n",
      "tensor(0.8893)\n",
      "tensor(0.9195)\n",
      "tensor(0.9266)\n",
      "tensor(0.8802)\n",
      "tensor(0.9020)\n",
      "tensor(0.8619)\n",
      "tensor(0.9859)\n",
      "tensor(0.9595)\n",
      "tensor(0.9043)\n",
      "tensor(1.0446)\n",
      "tensor(0.9116)\n",
      "tensor(0.8248)\n",
      "tensor(0.9065)\n",
      "tensor(0.7937)\n",
      "tensor(0.8863)\n",
      "tensor(0.8656)\n",
      "tensor(1.0949)\n",
      "tensor(0.8400)\n",
      "tensor(0.8809)\n",
      "tensor(0.8964)\n",
      "tensor(0.8957)\n",
      "tensor(0.9127)\n",
      "tensor(0.8815)\n",
      "tensor(0.8895)\n",
      "tensor(0.9150)\n",
      "tensor(0.9294)\n",
      "tensor(0.8981)\n",
      "tensor(0.9232)\n",
      "tensor(0.9532)\n",
      "tensor(1.0232)\n",
      "tensor(0.8381)\n",
      "tensor(0.8559)\n",
      "tensor(0.9568)\n",
      "tensor(1.3263)\n",
      "tensor(0.9435)\n",
      "tensor(0.8717)\n",
      "tensor(0.8938)\n",
      "tensor(0.9427)\n",
      "tensor(0.9212)\n",
      "tensor(0.9071)\n",
      "tensor(0.9943)\n",
      "tensor(1.2565)\n",
      "tensor(0.8312)\n",
      "tensor(0.8376)\n",
      "tensor(0.9208)\n",
      "tensor(0.9835)\n",
      "tensor(0.8449)\n",
      "tensor(0.9496)\n",
      "tensor(0.9627)\n",
      "tensor(0.9290)\n",
      "tensor(0.9043)\n",
      "tensor(0.9219)\n",
      "tensor(0.8760)\n",
      "tensor(0.8255)\n",
      "tensor(0.8688)\n",
      "tensor(0.9758)\n",
      "tensor(0.9444)\n",
      "tensor(0.8500)\n",
      "tensor(0.8989)\n",
      "tensor(0.8774)\n",
      "tensor(0.8604)\n",
      "tensor(0.8792)\n",
      "tensor(0.9664)\n",
      "tensor(0.8625)\n",
      "tensor(0.8637)\n",
      "tensor(0.9680)\n",
      "tensor(0.8567)\n",
      "tensor(0.8763)\n",
      "tensor(0.8645)\n"
     ]
    }
   ],
   "source": [
    "for (X, NL, mask) in data_loader:\n",
    "    A = eval_A(NL.int())*mask.unsqueeze(2)\n",
    "    print(X[:, :, -1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "min(input) -> Tensor\n",
      "\n",
      "Returns the minimum value of all elements in the :attr:`input` tensor.\n",
      "\n",
      ".. warning::\n",
      "    This function produces deterministic (sub)gradients unlike ``min(dim=0)``\n",
      "\n",
      "Args:\n",
      "    input (Tensor): the input tensor.\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> a = torch.randn(1, 3)\n",
      "    >>> a\n",
      "    tensor([[ 0.6750,  1.0857,  1.7197]])\n",
      "    >>> torch.min(a)\n",
      "    tensor(0.6750)\n",
      "\n",
      ".. function:: min(input, dim, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
      "   :noindex:\n",
      "\n",
      "Returns a namedtuple ``(values, indices)`` where ``values`` is the minimum\n",
      "value of each row of the :attr:`input` tensor in the given dimension\n",
      ":attr:`dim`. And ``indices`` is the index location of each minimum value found\n",
      "(argmin).\n",
      "\n",
      "If :attr:`keepdim` is ``True``, the output tensors are of the same size as\n",
      ":attr:`input` except in the dimension :attr:`dim` where they are of size 1.\n",
      "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
      "the output tensors having 1 fewer dimension than :attr:`input`.\n",
      "\n",
      ".. note:: If there are multiple minimal values in a reduced row then\n",
      "          the indices of the first minimal value are returned.\n",
      "\n",
      "Args:\n",
      "    input (Tensor): the input tensor.\n",
      "    dim (int): the dimension to reduce.\n",
      "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "\n",
      "Keyword args:\n",
      "    out (tuple, optional): the tuple of two output tensors (min, min_indices)\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> a = torch.randn(4, 4)\n",
      "    >>> a\n",
      "    tensor([[-0.6248,  1.1334, -1.1899, -0.2803],\n",
      "            [-1.4644, -0.2635, -0.3651,  0.6134],\n",
      "            [ 0.2457,  0.0384,  1.0128,  0.7015],\n",
      "            [-0.1153,  2.9849,  2.1458,  0.5788]])\n",
      "    >>> torch.min(a, 1)\n",
      "    torch.return_types.min(values=tensor([-1.1899, -1.4644,  0.0384, -0.1153]), indices=tensor([2, 0, 1, 0]))\n",
      "\n",
      ".. function:: min(input, other, *, out=None) -> Tensor\n",
      "   :noindex:\n",
      "\n",
      "See :func:`torch.minimum`.\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "? torch.min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GraphVAE(400, 3)\n",
    "# net.load_state_dict(torch.load(\"Saves/ecal_ep_60.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Loss: 0.00977 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58384\n",
      "Epoch : 2 Loss: 0.00569 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58381\n",
      "Epoch : 3 Loss: 0.00438 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58380\n",
      "Epoch : 4 Loss: 0.00445 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58379\n",
      "Epoch : 5 Loss: 0.00349 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58379\n",
      "Epoch : 6 Loss: 0.00425 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58380\n",
      "Epoch : 7 Loss: 0.00650 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58381\n",
      "Epoch : 8 Loss: 0.00299 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58379\n",
      "Epoch : 9 Loss: 0.00486 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58380\n",
      "Epoch : 10 Loss: 0.00344 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58378\n",
      "Epoch : 11 Loss: 0.00007 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58376\n",
      "Epoch : 12 Loss: 0.00272 E mse: 0.03432 Hit mse: 0.00998 L2: 2.58379\n",
      "Epoch : 13 Loss: 0.00329 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58379\n",
      "Epoch : 14 Loss: 0.00296 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58379\n",
      "Epoch : 15 Loss: 0.00567 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58380\n",
      "Epoch : 16 Loss: 0.00191 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58378\n",
      "Epoch : 17 Loss: 0.00302 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58378\n",
      "Epoch : 18 Loss: 0.00437 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58380\n",
      "Epoch : 19 Loss: 0.00405 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58380\n",
      "Epoch : 20 Loss: 0.00210 E mse: 0.03432 Hit mse: 0.00997 L2: 2.58378\n"
     ]
    }
   ],
   "source": [
    "train_loop2(net, 20, 200, 5e-4, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"Saves/ecal_ep_60.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_img3(Y, mask):\n",
    "    xhit, yhit = Y[:, :, 0], Y[:, :, 1]\n",
    "    val = Y[:, :, 2]/50.\n",
    "    \n",
    "    xhit = (xhit % 125).int()\n",
    "    yhit = (yhit % 125).int()\n",
    "    \n",
    "    mask = mask*torch.arange(1, 0, -1./400)**2\n",
    "    # mask = mask*torch.exp(-torch.arange(400))\n",
    "    ecal = torch.zeros((Y.shape[0], 125, 125))\n",
    "    ecal[\n",
    "        torch.arange(Y.shape[0]).unsqueeze(1),\n",
    "        xhit,\n",
    "        yhit\n",
    "    ] = mask #*val\n",
    "    \n",
    "    return ecal\n",
    "\n",
    "def reconstruct_img2(Y, mask):\n",
    "    xhit, yhit = (Y[:, :, 0])*125, (Y[:, :, 1])*125\n",
    "    ener = ((Y[:, :, 2] + 10))**5\n",
    "    \n",
    "    xhit = (xhit % 125).int()\n",
    "    yhit = (yhit % 125).int()\n",
    "    \n",
    "    ecal = torch.zeros((Y.shape[0], 125, 125))\n",
    "    ecal[\n",
    "        torch.arange(Y.shape[0]).unsqueeze(1),\n",
    "        xhit,\n",
    "        yhit\n",
    "    ] = mask*ener\n",
    "    \n",
    "    return ecal\n",
    "\n",
    "def loss_infer2(net, X, A, mask):\n",
    "    \"\"\"\n",
    "    Inference loss function\n",
    "    \"\"\"\n",
    "    # Reconstructed nodes and edges\n",
    "    Y, A2, mu, logvar, L1, L2 = net(X, A, mask)\n",
    "    # Convert back to image\n",
    "    ecal = reconstruct_img2(Y, mask)\n",
    "    \n",
    "    mse = torch.nn.MSELoss()\n",
    "    return mse(X, Y), ecal, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = GraphVAE(400, 3)\n",
    "net.load_state_dict(torch.load(\"Saves/ecal_ep_60.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_train_dataset()\n",
    "data_loader = torch.utils.data.DataLoader(dataset, 200, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (X, NL, mask) in data_loader:\n",
    "    X = X\n",
    "    A = eval_A(NL.int()) * mask.unsqueeze(2)\n",
    "    mask = mask\n",
    "    with torch.no_grad():\n",
    "        # Original samples\n",
    "        img1 = reconstruct_img2(X, mask)\n",
    "        # VAE-generated samples\n",
    "        L, img2, A2 = loss_infer2(net, X, A, mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(153270.7500), tensor(0.))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.max(), img1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(100000.), tensor(0.))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2.max(), img2.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img1[0]*(256))\n",
    "ax[1].imshow(img2[0]*(256))\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('Report/Figures/Gluon_reconstructed.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139306, 125, 125, 3)\n"
     ]
    }
   ],
   "source": [
    "f = h5.File(\"quark-gluon_data-set_n139306.hdf5\")\n",
    "print(f['X_jets'].shape)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_load import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "with h5.File('quark_jets_ecal.h5', 'w') as g:\n",
    "    f = h5.File('quark-gluon_data-set_n139306.hdf5', 'r')\n",
    "    \n",
    "    dset = g.create_dataset('x', shape=(0, 125, 125, 3), dtype=np.float32,\n",
    "                            maxshape=(None, 125, 125, 3))\n",
    "    L = 100_000\n",
    "    w = 10_000\n",
    "\n",
    "    for i in range(10):\n",
    "        x, y = f['X_jets'][i*w: (i+1)*w], f['y'][i*w: (i+1)*w]\n",
    "        x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "        (ind_0,) = torch.nonzero(y==0, as_tuple=True)\n",
    "        x = x[ind_0]\n",
    "        curr_shape = dset.shape[0]\n",
    "        dset.resize((curr_shape+x.shape[0], 125, 125, 3))\n",
    "        dset[curr_shape:, :, :] = x\n",
    "    print(dset.shape[0])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.9078,  0.0000, -2.3026,  0.1823])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(\n",
    "    [1e-3, 0., 0.1, 1.2]\n",
    ")\n",
    "x2 = torch.nan_to_num(x.log(), neginf=0.)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "with h5.File('gluon_jets_ecal.h5', 'w') as g:\n",
    "    f = h5.File('quark-gluon_data-set_n139306.hdf5', 'r')\n",
    "    \n",
    "    dset = g.create_dataset('x', shape=(0, 125, 125, 3), dtype=np.float32,\n",
    "                            maxshape=(None, 125, 125, 3))\n",
    "    L = 100_000\n",
    "    w = 10_000\n",
    "\n",
    "    for i in range(10):\n",
    "        x, y = f['X_jets'][i*w: (i+1)*w], f['y'][i*w: (i+1)*w]\n",
    "        x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "        (ind_0,) = torch.nonzero(y==1, as_tuple=True)\n",
    "        x = x[ind_0]\n",
    "        curr_shape = dset.shape[0]\n",
    "        dset.resize((curr_shape+x.shape[0], 125, 125, 3))\n",
    "        dset[curr_shape:, :, :] = x\n",
    "    print(dset.shape[0])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates a 3-channel heavy-duty dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5.File('quark_jets_ecal.h5') as g:\n",
    "#     with h5.File('quark_3chan_graph.h5', 'w') as h:\n",
    "#         X_dset = h.create_dataset('X', shape=(0, 1000, 4), dtype=np.float32,\n",
    "#                             maxshape=(None, 1000, 4))\n",
    "#         A_dset = h.create_dataset('A', shape=(0, 1000, 1000), dtype=np.float32,\n",
    "#                             maxshape=(None, 1000, 1000))\n",
    "#         mask_dset = h.create_dataset('mask', shape=(0, 1000), dtype=np.float32,\n",
    "#                             maxshape=(None, 1000))\n",
    "        \n",
    "#         device = torch.device(\"cpu\")\n",
    "#         w = 2000\n",
    "#         for i in range(25):\n",
    "#             x = g['x'][i*w: (i+1)*w]\n",
    "#             x = torch.from_numpy(x).to(device)\n",
    "#             X, A, mask, _ = preprocess(x, device)\n",
    "            \n",
    "#             curr_shape = X_dset.shape[0]\n",
    "                \n",
    "#             X_dset.resize((curr_shape+w, 1000, 4))\n",
    "#             A_dset.resize((curr_shape+w, 1000, 1000))\n",
    "#             mask_dset.resize((curr_shape+w, 1000))\n",
    "            \n",
    "#             X_dset[curr_shape:, :, :] = X.to(\"cpu\").numpy()\n",
    "#             A_dset[curr_shape:, :, :] = A.to(\"cpu\").numpy()\n",
    "#             mask_dset[curr_shape:, :] = mask.to(\"cpu\").numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates a smaller single channel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.bool tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "with h5.File('quark_jets_ecal.h5') as g:\n",
    "    with h5.File('quark_ecal_graph.h5', 'w') as h:\n",
    "        X_dset = h.create_dataset('X', shape=(0, 400, 3), dtype=np.float32,\n",
    "                            maxshape=(None, 400, 3), compression=\"gzip\")\n",
    "        NL_dset = h.create_dataset('NL', shape=(0, 400, 6), dtype=np.float32,\n",
    "                            maxshape=(None, 400, 6), compression=\"gzip\")\n",
    "        mask_dset = h.create_dataset('mask', shape=(0, 400), dtype=np.float32,\n",
    "                            maxshape=(None, 400), compression=\"gzip\")\n",
    "        \n",
    "        device = \"cpu\"\n",
    "        w = 2000\n",
    "        for i in range(25):\n",
    "            x = g['x'][i*w: (i+1)*w]\n",
    "            x[x < 1e-3] = 0\n",
    "            x = torch.from_numpy(x)[:, :, :, 1].to(device)\n",
    "            X, A, mask, _ = preprocess(x, device)\n",
    "            \n",
    "            NL = torch.argsort(A, 1, True)[:, :6, :].int().permute(0, 2, 1)\n",
    "            \n",
    "            curr_shape = X_dset.shape[0]\n",
    "            X_dset.resize((curr_shape+w, 400, 3))\n",
    "            NL_dset.resize((curr_shape+w, 400, 6))\n",
    "            mask_dset.resize((curr_shape+w, 400))\n",
    "            \n",
    "            X_dset[curr_shape:, :, :] = X.to(\"cpu\").numpy()\n",
    "            NL_dset[curr_shape:, :, :] = NL.to(\"cpu\").numpy()\n",
    "            mask_dset[curr_shape:, :] = mask.float().to(\"cpu\").numpy()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean E:  tensor(-1.9866) Std E:  tensor(4.8814)\n",
      "Mean E:  tensor(-1.9837) Std E:  tensor(4.8877)\n",
      "Mean E:  tensor(-2.0412) Std E:  tensor(4.8623)\n",
      "Mean E:  tensor(-2.0492) Std E:  tensor(4.8592)\n",
      "Mean E:  tensor(-2.2505) Std E:  tensor(4.7457)\n"
     ]
    }
   ],
   "source": [
    "# Check minimum and maximum energies\n",
    "with h5.File('quark_ecal_graph.h5') as g:\n",
    "    device = \"cpu\"\n",
    "    w = 10_000\n",
    "    for i in range(5):\n",
    "        X = g['X'][i*w: (i+1)*w]\n",
    "        mask = torch.from_numpy(g['mask'][i*w: (i+1)*w])\n",
    "        counts = mask.sum(1)\n",
    "        # Studying the typical energies\n",
    "        E_hit = torch.from_numpy(X[:, :, 2])\n",
    "        log_E_hit = torch.nan_to_num(torch.log(E_hit), neginf=0.)\n",
    "        \n",
    "        print(\"Mean E: \", log_E_hit.mean(), \n",
    "              \"Std E: \", (log_E_hit.std(1)*(20/(counts**0.5))).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.285641521180462\n",
      "3.622113757801675\n"
     ]
    }
   ],
   "source": [
    "print(0.5*(np.log(1.4) + np.log(1e-3)))\n",
    "print(0.5*(np.log(1.4) - np.log(1e-3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File('quark_ecal_graph.h5') as g:\n",
    "    with h5.File('quark_ecal_graph_normalized.h5', 'w') as h:\n",
    "        X_dset = h.create_dataset('X', shape=(0, 400, 3), dtype=np.float32,\n",
    "                            maxshape=(None, 400, 3), compression=\"gzip\")\n",
    "        NL_dset = h.create_dataset('NL', shape=(0, 400, 6), dtype=np.float32,\n",
    "                            maxshape=(None, 400, 6), compression=\"gzip\")\n",
    "        mask_dset = h.create_dataset('mask', shape=(0, 400), dtype=np.float32,\n",
    "                            maxshape=(None, 400), compression=\"gzip\")\n",
    "        \n",
    "        device = \"cpu\"\n",
    "        w = 2000\n",
    "        for i in range(25):\n",
    "            X = g['X'][i*w: (i+1)*w]\n",
    "            NL = g['NL'][i*w: (i+1)*w]\n",
    "            mask = g['mask'][i*w: (i+1)*w]\n",
    "            \n",
    "            X = torch.from_numpy(X)            \n",
    "            X[:, :, :2] = X[:, :, :2]/62.5 - 1 # Pixels in (-1, 1) range\n",
    "            X[:, :, 2] = (torch.nan_to_num(X[:, :, 2].log(), neginf=0.) + 2)/4.8 \n",
    "            # Energies in (-1, 1)\n",
    "            \n",
    "            curr_shape = X_dset.shape[0]\n",
    "            \n",
    "            X_dset.resize((curr_shape+w, 400, 3))\n",
    "            NL_dset.resize((curr_shape+w, 400, 6))\n",
    "            mask_dset.resize((curr_shape+w, 400))\n",
    "            \n",
    "            X_dset[curr_shape:, :, :] = X.to(\"cpu\").numpy()\n",
    "            NL_dset[curr_shape:, :, :] = NL\n",
    "            mask_dset[curr_shape:, :] = mask\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_train_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
